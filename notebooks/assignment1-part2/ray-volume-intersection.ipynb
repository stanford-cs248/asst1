{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "40e8f0f1",
         "metadata": {},
         "source": [
            "# Assignment 1 Part 2: Ray Volume Intersection\n",
            "\n",
            "In this assignment, you are going to learn about representation of geometry as occupancy grid and how to render it."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "2f9af6d2",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "objc[36310]: Class GLFWHelper is implemented in both /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x10ef6d248) and /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x13580fa28). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
                  "objc[36310]: Class GLFWApplicationDelegate is implemented in both /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x10ef6d298) and /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x13580fa78). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
                  "objc[36310]: Class GLFWWindowDelegate is implemented in both /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x10ef6d2c0) and /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x13580faa0). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
                  "objc[36310]: Class GLFWContentView is implemented in both /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x10ef6d310) and /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x13580faf0). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
                  "objc[36310]: Class GLFWWindow is implemented in both /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x10ef6d388) and /Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x13580fb68). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n"
               ]
            }
         ],
         "source": [
            "import pathlib\n",
            "import numpy as np\n",
            "from matplotlib import pyplot as plt\n",
            "\n",
            "import slangpy as spy\n",
            "from pyglm import glm\n",
            "import open3d as o3d\n",
            "from tqdm.notebook import tqdm\n",
            "\n",
            "from cs248a_renderer import setup_device, RendererModules\n",
            "from cs248a_renderer.model.mesh import Mesh, create_triangle_buf\n",
            "from cs248a_renderer.model.volumes import DenseVolume, create_volume_buf\n",
            "from cs248a_renderer.model.scene import Scene\n",
            "from cs248a_renderer.model.bvh import BVH, create_bvh_node_buf\n",
            "from cs248a_renderer.renderer.core_renderer import Renderer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "43dda5b4",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[\u001b[36mINFO\u001b[0m] (\u001b[90mrhi\u001b[0m) layer: CreateDevice: Debug layer is enabled.\n",
                  "[\u001b[33mWARN\u001b[0m] No supported shader model found, pretending to support sm_6_0.\n",
                  "[\u001b[33mWARN\u001b[0m] Slang compiler warnings:\n",
                  "/Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/src/cs248a_renderer/slang_shaders/renderer.slang(65): warning 41016: use of uninitialized variable 'result'\n",
                  "    float3 color = simpleMaterial.shade(ray, result);\n",
                  "                                       ^\n",
                  "/Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/src/cs248a_renderer/slang_shaders/renderer.slang(59): warning 41016: use of uninitialized variable 'result'\n",
                  "        return float4(result.normal * 0.5 + 0.5, 1.0);\n",
                  "                                    ^\n",
                  "/Users/fangjun/Documents/stanford/cs248a-winter-2026/cs248a-renderer-internal/src/cs248a_renderer/slang_shaders/renderer.slang(53): warning 41016: use of uninitialized variable 'result'\n",
                  "        return float4(float3(result.t), 1.0);\n",
                  "                            ^\n",
                  "\n"
               ]
            }
         ],
         "source": [
            "# We setup the device and renderer similar to part 1\n",
            "bvh_shader_path = pathlib.Path.cwd() / \"shaders\"\n",
            "device = setup_device([bvh_shader_path])\n",
            "renderer_modules = RendererModules(device)\n",
            "assignment1_module = spy.Module.load_from_file(\n",
            "    device=device,\n",
            "    path=\"assignment1.slang\",\n",
            "    link=[renderer_modules.texture_module]\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "2bf72b23",
         "metadata": {},
         "source": [
            "## Volumetric Representation of Shapes\n",
            "\n",
            "Volumetric shapes fill a regular 3D grid, where each cell of grid represent a tiny cube of space storing properties of a point in 3D space. Simplest way to represent a surface would by by encoding the properties of ocupancy (whether a surface exists at this point or not) and color (at the surface point) at a voxel, essentially having a grid of size HxWxD and at each grid cell (called as a 'voxel') we'd have a vector of size 4 to encode RGB color and occupancy (0/1)."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "7fe50bde",
         "metadata": {},
         "source": [
            "### Visualizing Occupancy grids\n",
            "\n",
            "As you might have guessed, the grid-like representation introduces quantization artefacts since a surface is continuous by nature (we're going learn to retain this property when we'll render SDFs). But what if I want to know the color and occupancy at any arbitrary point?\n",
            "\n",
            "To accomplish task, we turn to interpolation techniques. In this exercise, we are going to visualize a slice of volume using two types of interpolations: nearest and tri-linear interpolation."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "ba3276d5",
         "metadata": {},
         "source": [
            "Download the `sdf_volume_low_res.npy` file from the  assignment 1 resources folder: https://drive.google.com/drive/folders/1IHUzNzK4TwybdGrdUOpoYpKfIZEC9VVY?usp=share_link and save it in the `resources` directory.\n",
            "\n",
            "This volume is stored in a 3D numpy array of size 32x32x32, where each voxel contains a single float value representing occupancy at that point. For now, you can assume the occupancy value is 1.0 inside the surface and 0.0 outside the surface.\n",
            "\n",
            "In the following cell, we're also loading a default color for the volume (red). You can ignore the color part for now since we're only interested in visualizing the occupancy values."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "2df2edb8",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(32, 32, 32, 4)"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Load the volume density data from the provided .npy file.\n",
            "volume_density = np.load(\"../../resources/sdf_volume_low_res.npy\")\n",
            "# Fill the RGB channel with colors.\n",
            "VOLUME_COLOR = [1.0, 0.0, 0.0]\n",
            "volume_color = np.full(volume_density.shape + (3,), VOLUME_COLOR, dtype=np.float32)\n",
            "np_volume = np.concatenate(\n",
            "    [volume_color, volume_density[..., np.newaxis]], axis=-1\n",
            ")\n",
            "np_volume.shape"
         ]
      },
      {
         "attachments": {
            "image.png": {
               "image/png": "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"
            }
         },
         "cell_type": "markdown",
         "id": "5f79bd1e",
         "metadata": {},
         "source": [
            "### Nearest Neighbor Interpolation\n",
            "\n",
            "Nearest Neighbor is the simplest way to assign properties to a point **p**. Instead of blending values, we simply look for the single voxel **v** that is physically closest to **p** and adopt its properties (like color and occupancy) entirely.\n",
            "\n",
            "#### How it Works\n",
            "Imagine every voxel is the center of a small cube of influence. If point **p** falls anywhere inside that cube, it \"snaps\" to that voxel's value. \n",
            "* It is computationally very fast because it requires no averaging.\n",
            "* It effectively treats the volume as a collection of discrete blocks rather than a continuous field.\n",
            "\n",
            "Now, implement the `pointSample` function in `src/cs248a_renderer/slang_shaders/texture/texture.slang` to perform nearest neighbor sampling. The function is taking a `SharedTexture3D` object and a 3D coordinate `uvw` (in [0, 1] range) as input and should return the voxel value at the nearest neighbor.\n",
            "\n",
            "To get the voxel value from the `SharedTexture3D` object, you can use the `getBufferValue` and pass in the voxel coorinates as a `uint3` object. The voxel coordinates should range from (0, 0, 0) to (size.x-1, size.y-1, size.z-1).\n",
            "\n",
            "Once you implement the nearest neighbor sampling, you should get a visualization similar to the one below:\n",
            "\n",
            "![image.png](attachment:image.png)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "f9776e55",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABOJJREFUeJzt1bEBgDAMwLCU/39OJ/wCDNIF3nx2dwcAZub5OgCA/zAFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAJjXBe8DBwZ+t6mMAAAAAElFTkSuQmCC",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "OUTPUT_IMG_SIZE = (512, 512)\n",
            "output_image = device.create_texture(\n",
            "    type=spy.TextureType.texture_2d,\n",
            "    format=spy.Format.rgba32_float,\n",
            "    usage=spy.TextureUsage.unordered_access,\n",
            "    width=OUTPUT_IMG_SIZE[0],\n",
            "    height=OUTPUT_IMG_SIZE[1],\n",
            ")\n",
            "np_volume_reshape = np_volume.reshape(-1, 4)\n",
            "volume_tex_buf = spy.NDBuffer(\n",
            "    device=device,\n",
            "    dtype=assignment1_module.float4,\n",
            "    shape=(np_volume_reshape.shape[0], )\n",
            ")\n",
            "volume_tex_buf.copy_from_numpy(np_volume_reshape)\n",
            "assignment1_module.sliceNearestSample(\n",
            "    tid=spy.grid(OUTPUT_IMG_SIZE),\n",
            "    canvasSize=[OUTPUT_IMG_SIZE[0], OUTPUT_IMG_SIZE[1]],\n",
            "    volumeTexBuf={\n",
            "        \"buffer\": volume_tex_buf\n",
            "    },\n",
            "    volumeTex={\n",
            "        \"size\": [np_volume.shape[2], np_volume.shape[1], np_volume.shape[0]],\n",
            "        \"offset\": 0\n",
            "    },\n",
            "    slice=0.25,\n",
            "    _result=output_image\n",
            ")\n",
            "plt.imshow(np.flipud(output_image.to_numpy()))\n",
            "plt.axis('off')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a56ad50f",
         "metadata": {},
         "source": [
            "### Tri-Linear Interpolation\n",
            "While **Nearest Neighbor** is fast, it creates a \"stepped\" environment where properties jump abruptly from one voxel to the next. To achieve smooth surfaces and realistic lighting, we use **Tri-Linear Interpolation**, which treats the space between voxels as a continuous blend rather than a series of hard boundaries.\n",
            "\n",
            "Instead of \"snapping\" to the single closest voxel, we look at the **8 surrounding voxels** that form a cube (or \"cell\") around point **p**. We then calculate a weighted average of their properties based on **p**'s position within that cube.\n",
            "  \n",
            "Implement the `trilinearSample` function in `src/cs248a_renderer/slang_shaders/texture/texture.slang` to perform nearest neighbor sampling. The function is taking a `SharedTexture3D` object and a 3D coordinate `uvw` (in [0, 1] range) as input and should return the voxel value interpolated trilinearly using the surrounding voxels.\n",
            "\n",
            "To get the voxel value from the `SharedTexture3D` object, you can use the `getBufferValue` and pass in the voxel coorinates as a `uint3` object. The voxel coordinates should range from (0, 0, 0) to (size.x-1, size.y-1, size.z-1).\n",
            "\n",
            "Once you implement the trilinear sampling, you should get a visualization similar to the one below:\n",
            "\n",
            "![trilinear](../../assets/trilinear.png)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "de954f3c",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABOJJREFUeJzt1bEBgDAMwLCU/39OJ/wCDNIF3nx2dwcAZub5OgCA/zAFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAJjXBe8DBwZ+t6mMAAAAAElFTkSuQmCC",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "OUTPUT_IMG_SIZE = (512, 512)\n",
            "output_image = device.create_texture(\n",
            "    type=spy.TextureType.texture_2d,\n",
            "    format=spy.Format.rgba32_float,\n",
            "    usage=spy.TextureUsage.unordered_access,\n",
            "    width=OUTPUT_IMG_SIZE[0],\n",
            "    height=OUTPUT_IMG_SIZE[1],\n",
            ")\n",
            "np_volume_reshape = np_volume.reshape(-1, 4)\n",
            "volume_tex_buf = spy.NDBuffer(\n",
            "    device=device,\n",
            "    dtype=assignment1_module.float4,\n",
            "    shape=(np_volume_reshape.shape[0], )\n",
            ")\n",
            "volume_tex_buf.copy_from_numpy(np_volume_reshape)\n",
            "assignment1_module.sliceTrilinearSample(\n",
            "    tid=spy.grid(OUTPUT_IMG_SIZE),\n",
            "    canvasSize=[OUTPUT_IMG_SIZE[0], OUTPUT_IMG_SIZE[1]],\n",
            "    volumeTexBuf={\n",
            "        \"buffer\": volume_tex_buf\n",
            "    },\n",
            "    volumeTex={\n",
            "        \"size\": [np_volume.shape[2], np_volume.shape[1], np_volume.shape[0]],\n",
            "        \"offset\": 0\n",
            "    },\n",
            "    slice=0.25,\n",
            "    _result=output_image\n",
            ")\n",
            "plt.imshow(np.flipud(output_image.to_numpy()))\n",
            "plt.axis('off')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a082a6f3",
         "metadata": {},
         "source": [
            "## Rendering a Volume\n",
            "\n",
            "As we've seen previously, rendering any surface requires us to determine the point of ray-surface intersection. You've previously implemented ray-triangle intersection. Now, we are going to use the same principles to determine ray-voxel intersection point."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "ef146b04",
         "metadata": {},
         "outputs": [],
         "source": [
            "# We are creating a dense volume SceneObject and storing the numpy \n",
            "# volume data in it. Voxel size is 1/16 units. Our data is \n",
            "# stored in a 32x32x32 voxel grid, so the total size of our volume is \n",
            "# 2x2x2 units.\n",
            "volume = DenseVolume(\n",
            "    name=\"volume\",\n",
            "    data=np_volume,\n",
            "    properties={\n",
            "        \"voxel_size\": 1 / 16,\n",
            "        \"pivot\": (0.5, 0.5, 0.5),\n",
            "    }\n",
            ")\n",
            "volume.transform.position = glm.vec3(0.0, 0.0, 0.0)\n",
            "volume.transform.rotation = glm.quat(1.0, 0.0, 0.0, 0.0)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "f6993a6c",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "SceneObject(name=root, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
                     "  SceneObject(name=volume, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
                     "  ])\n",
                     "])"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# We'll load the Volume model into our scene.\n",
            "scene = Scene()\n",
            "scene.add_object(volume)\n",
            "cam = scene.camera\n",
            "cam_pos = glm.vec3(3.0, 2.0, 3.0)\n",
            "cam.transform.position = cam_pos\n",
            "cam.transform.rotation = glm.quatLookAt(glm.normalize(-cam_pos), glm.vec3(0.0, 1.0, 0.0))\n",
            "scene"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "2a7c72c6",
         "metadata": {},
         "outputs": [],
         "source": [
            "OUTPUT_IMG_SIZE = (512, 512)\n",
            "output_image = device.create_texture(\n",
            "    type=spy.TextureType.texture_2d,\n",
            "    format=spy.Format.rgba32_float,\n",
            "    usage=spy.TextureUsage.unordered_access,\n",
            "    width=OUTPUT_IMG_SIZE[0],\n",
            "    height=OUTPUT_IMG_SIZE[1],\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1667ff0f",
         "metadata": {},
         "source": [
            "### Ray Marching to find a Hit Point\n",
            "\n",
            "In the case of triangles, we could analytically determine the point of ray-triangle intersection. However, in the case of voxel representation this is not possible. Therefore, we have evaluation each point along the ray until we find an occupied point. We are going to use our knowledge of sampling to determine the occupancy of a 3D point in a voxel grid.\n",
            "\n",
            "Implement the `hit` function for the primitive of volume defined in `src/cs248a_renderer/slang_shaders/primitive/volume.slang`. It accepts a `ray` and `volumeTexBuf` containing the volume data. To sample from the volume use `volumeTexBuf.trilinearSample(tex, uvw)`, where `uvw` is texture coordinate ranging from 0-1."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "4dfe577a",
         "metadata": {},
         "outputs": [],
         "source": [
            "renderer = Renderer(\n",
            "    device=device,\n",
            "    render_texture=output_image,\n",
            "    render_modules=renderer_modules\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "29688389",
         "metadata": {},
         "source": [
            "Upon implementing the ray-volume `hit` function, now you're ready to render the volumes in the scene. Remember that the `hit` function returns a `RayHitResult` struct that stores the point along the ray that hit the surface. Now, we are going to use this to render all the volumes in the scene.\n",
            "\n",
            "In `src/cs248a_renderer/slang_shaders/renderer.slang` implement the Ray-Volume intersection test in `sample` function by cycling over all the volumes in the scene. Note that, this function also contains the ray-triangle intersection test from Part 1 of this assignment. In the similar spirit, we continue to test over all the volumes in the scene.\n",
            "\n",
            "![depth.png](../../assets/depth.png)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "96da893c",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0714285..1.0].\n"
               ]
            },
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "renderer.load_volumes(scene)\n",
            "renderer.render(\n",
            "    view_mat=cam.view_matrix(),\n",
            "    fov=cam.fov,\n",
            "    render_depth=True,\n",
            ")\n",
            "output_np = output_image.to_numpy()\n",
            "output_np[:, :, :3] -= 3\n",
            "output_np[:, :, :3] /= 2.8\n",
            "plt.imshow(np.flipud(output_np))\n",
            "plt.axis('off')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e7f127e2",
         "metadata": {},
         "source": [
            "### Computing Normal at Hit Point\n",
            "\n",
            "Normal at a surface point is defined as the direction along with there maximum change in the occupancy function. For eg. in the case of planar surfaces like triangles, the occupancy function transitions abruptly from 0 (outside) to 1 (inside). Since any movement within the plane of the triangle results in no change in occupancy, the direction of maximum change must be strictly perpendicular to the surface, hence the cross-product of plane in which the triangle exists is its normal.\n",
            "\n",
            "#### Extension to Voxels\n",
            "In a 3D voxel grid, the occupancy function $O(x, y, z)$ is discrete. We extend the concept of \"maximum change\" by treating the grid as a scalar field and computing the **gradient** ($\\nabla O$) using **finite differences**.\n",
            "\n",
            "##### 1. Central Difference Approximation\n",
            "At a hit point within the grid, the normal is estimated by comparing the occupancy values of neighboring voxels along each axis:\n",
            "\n",
            "* **x-axis:** $g_x = O(x+\\Delta, y, z) - O(x-\\Delta, y, z)$\n",
            "* **y-axis:** $g_y = O(x, y+\\Delta, z) - O(x, y-\\Delta, z)$\n",
            "* **z-axis:** $g_z = O(x, y, z+\\Delta) - O(x, y, z-\\Delta)$\n",
            "\n",
            "\n",
            "\n",
            "##### 2. Normalization\n",
            "The final surface normal is the unit vector of this gradient:\n",
            "$$\\mathbf{n} = -\\text{normalize}(g_x, g_y, g_z)$$\n",
            "\n",
            "Inside the ray-volume `hit` function, we are now going to return the estimated normal along with the `t` value in the `RayHitResult`.\n",
            "\n",
            "A correct implementation will render a normal of the Volume like this:\n",
            "\n",
            "![normal.png](../../assets/normal.png)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "cbda2a4f",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABOJJREFUeJzt1bEBgDAMwLCU/39OJ/wCDNIF3nx2dwcAZub5OgCA/zAFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAJjXBe8DBwZ+t6mMAAAAAElFTkSuQmCC",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "renderer.load_volumes(scene)\n",
            "renderer.render(\n",
            "    view_mat=cam.view_matrix(),\n",
            "    fov=cam.fov,\n",
            "    render_normal=True,\n",
            ")\n",
            "output_np = output_image.to_numpy()\n",
            "plt.imshow(np.flipud(output_np))\n",
            "plt.axis('off')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b01cb975",
         "metadata": {},
         "source": [
            "### Finally, let's render the occupancy grid\n",
            "\n",
            "If all the implementaiton above is correct, the renderer should now render an image like this:\n",
            "\n",
            "![depth.png](../../assets/occ.png)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "953ee4de",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "renderer.load_volumes(scene)\n",
            "renderer.render(\n",
            "    view_mat=cam.view_matrix(),\n",
            "    fov=cam.fov,\n",
            ")\n",
            "output_np = output_image.to_numpy()\n",
            "plt.imshow(np.flipud(output_np))\n",
            "plt.axis('off')\n",
            "plt.show()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.9"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
